{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import datetime\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> get data from database</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MySQL connection is closed\n"
     ]
    }
   ],
   "source": [
    "import mysql.connector\n",
    "from mysql.connector import Error\n",
    "records=[]\n",
    "try:\n",
    "    connection = mysql.connector.connect(host='localhost',\n",
    "                                         database='optimatets',\n",
    "                                         user='root',\n",
    "                                         password='')\n",
    "    sql_select_Query=[]\n",
    "    sql_select_Query.append( \"select * from bookings\")\n",
    "    sql_select_Query.append(\"select * from driver_vehicle\")\n",
    "    sql_select_Query.append(\"select * from tracking\")\n",
    "    sql_select_Query.append(\"select * from vehicles\")\n",
    "    sql_select_Query.append(\"select * from vehicle_types\")\n",
    "    for req in sql_select_Query:\n",
    "        cursor = connection.cursor()\n",
    "        cursor.execute(req)\n",
    "        records.append( cursor.fetchall())    \n",
    "\n",
    "except Error as e:\n",
    "    print(\"Error reading data from MySQL table\", e)\n",
    "finally:\n",
    "    if (connection.is_connected()):\n",
    "        connection.close()\n",
    "        cursor.close()\n",
    "        print(\"MySQL connection is closed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bookings=pd.DataFrame(records[0],columns=['id', 'book_type', 'promo_id' , 'type_id' , 'accept_status', 'total_weight', 'company_id', 'date_time', 'user_id', 'vehicle_id', 'driver_id', 'customer_id', 'pickup', 'dropoff', 'duration', 'pickup_addr', 'dest_addr','note', 'travellers', 'status', 'payment', 'created_at', 'updated_at', 'deleted_at'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=bookings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>book_type</th>\n",
       "      <th>promo_id</th>\n",
       "      <th>type_id</th>\n",
       "      <th>accept_status</th>\n",
       "      <th>total_weight</th>\n",
       "      <th>company_id</th>\n",
       "      <th>date_time</th>\n",
       "      <th>user_id</th>\n",
       "      <th>vehicle_id</th>\n",
       "      <th>...</th>\n",
       "      <th>duration</th>\n",
       "      <th>pickup_addr</th>\n",
       "      <th>dest_addr</th>\n",
       "      <th>note</th>\n",
       "      <th>travellers</th>\n",
       "      <th>status</th>\n",
       "      <th>payment</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>deleted_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>s</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "      <td>53</td>\n",
       "      <td>30.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2019-07-03 12:01:13</td>\n",
       "      <td>53</td>\n",
       "      <td>21.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>TUNIS</td>\n",
       "      <td>SOUSSE</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-07-01 11:02:24</td>\n",
       "      <td>2019-07-29 12:20:08</td>\n",
       "      <td>2019-07-29 12:20:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>s</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "      <td>53</td>\n",
       "      <td>20.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2019-07-06 07:09:11</td>\n",
       "      <td>53</td>\n",
       "      <td>21.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>SFAX</td>\n",
       "      <td>TUNIS</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-07-04 14:13:04</td>\n",
       "      <td>2019-07-29 12:20:16</td>\n",
       "      <td>2019-07-29 12:20:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>s</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>60</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2019-07-08 08:21:49</td>\n",
       "      <td>60</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>TUNIS</td>\n",
       "      <td>BIZERTE</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-07-04 14:23:12</td>\n",
       "      <td>2019-07-29 12:20:25</td>\n",
       "      <td>2019-07-29 12:20:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>s</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>51</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2019-07-11 09:06:34</td>\n",
       "      <td>51</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>TUNIS</td>\n",
       "      <td>SOUSSE</td>\n",
       "      <td>Bien reçu. Je note çà appele moi sur 22222222</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-07-09 11:08:28</td>\n",
       "      <td>2019-07-29 12:21:40</td>\n",
       "      <td>2019-07-29 12:21:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>s</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "      <td>60</td>\n",
       "      <td>25.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2019-07-14 12:24:05</td>\n",
       "      <td>60</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>TUNIS</td>\n",
       "      <td>MAHDIA</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-07-09 11:24:51</td>\n",
       "      <td>2019-07-29 12:21:47</td>\n",
       "      <td>2019-07-29 12:21:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>252</td>\n",
       "      <td>s</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-02-10 09:47:01</td>\n",
       "      <td>66</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>ARIANA</td>\n",
       "      <td>SFAX</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-02-07 09:46:38</td>\n",
       "      <td>2020-02-07 09:46:38</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>253</td>\n",
       "      <td>s</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-02-08 10:21:46</td>\n",
       "      <td>66</td>\n",
       "      <td>19.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>SFAX</td>\n",
       "      <td>TUNIS</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-02-07 10:21:36</td>\n",
       "      <td>2020-02-07 10:21:36</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>254</td>\n",
       "      <td>s</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-02-08 10:21:46</td>\n",
       "      <td>66</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>SFAX</td>\n",
       "      <td>TUNIS</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-02-07 10:21:43</td>\n",
       "      <td>2020-02-07 10:21:43</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>255</td>\n",
       "      <td>p</td>\n",
       "      <td>98.0</td>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2020-02-08 08:34:29</td>\n",
       "      <td>65</td>\n",
       "      <td>52.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>TUNIS</td>\n",
       "      <td>SFAX</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-02-07 15:35:24</td>\n",
       "      <td>2020-02-07 15:45:54</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>256</td>\n",
       "      <td>p</td>\n",
       "      <td>99.0</td>\n",
       "      <td>1</td>\n",
       "      <td>161</td>\n",
       "      <td>1.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>2020-02-11 13:37:00</td>\n",
       "      <td>161</td>\n",
       "      <td>51.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>TUNIS</td>\n",
       "      <td>SFAX</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-02-10 16:37:15</td>\n",
       "      <td>2020-02-10 16:38:21</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>197 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id book_type  promo_id  type_id  accept_status  total_weight  \\\n",
       "0      4         s       NaN       17             53          30.0   \n",
       "1      8         s       NaN       17             53          20.0   \n",
       "2      9         s       NaN        6             60          10.0   \n",
       "3     14         s       NaN        3             51           5.0   \n",
       "4     15         s       NaN       17             60          25.0   \n",
       "..   ...       ...       ...      ...            ...           ...   \n",
       "192  252         s       NaN        7              0          21.0   \n",
       "193  253         s       NaN        2              0           5.0   \n",
       "194  254         s       NaN        2              0           5.0   \n",
       "195  255         p      98.0        1             65           2.0   \n",
       "196  256         p      99.0        1            161           1.0   \n",
       "\n",
       "     company_id           date_time  user_id  vehicle_id  ...  duration  \\\n",
       "0          11.0 2019-07-03 12:01:13       53        21.0  ...      None   \n",
       "1          11.0 2019-07-06 07:09:11       53        21.0  ...      None   \n",
       "2          11.0 2019-07-08 08:21:49       60         7.0  ...      None   \n",
       "3          10.0 2019-07-11 09:06:34       51         3.0  ...      None   \n",
       "4          11.0 2019-07-14 12:24:05       60         7.0  ...      None   \n",
       "..          ...                 ...      ...         ...  ...       ...   \n",
       "192         NaN 2020-02-10 09:47:01       66         8.0  ...      None   \n",
       "193         NaN 2020-02-08 10:21:46       66        19.0  ...      None   \n",
       "194         NaN 2020-02-08 10:21:46       66        10.0  ...      None   \n",
       "195        13.0 2020-02-08 08:34:29       65        52.0  ...      None   \n",
       "196        56.0 2020-02-11 13:37:00      161        51.0  ...      None   \n",
       "\n",
       "     pickup_addr dest_addr                                           note  \\\n",
       "0          TUNIS    SOUSSE                                           None   \n",
       "1           SFAX     TUNIS                                           None   \n",
       "2          TUNIS   BIZERTE                                           None   \n",
       "3          TUNIS    SOUSSE  Bien reçu. Je note çà appele moi sur 22222222   \n",
       "4          TUNIS    MAHDIA                                           None   \n",
       "..           ...       ...                                            ...   \n",
       "192       ARIANA      SFAX                                           None   \n",
       "193         SFAX     TUNIS                                           None   \n",
       "194         SFAX     TUNIS                                           None   \n",
       "195        TUNIS      SFAX                                           None   \n",
       "196        TUNIS      SFAX                                           None   \n",
       "\n",
       "    travellers status payment          created_at          updated_at  \\\n",
       "0            1      0       0 2019-07-01 11:02:24 2019-07-29 12:20:08   \n",
       "1            1      0       0 2019-07-04 14:13:04 2019-07-29 12:20:16   \n",
       "2            1      0       0 2019-07-04 14:23:12 2019-07-29 12:20:25   \n",
       "3            1      3       1 2019-07-09 11:08:28 2019-07-29 12:21:40   \n",
       "4            1      1       0 2019-07-09 11:24:51 2019-07-29 12:21:47   \n",
       "..         ...    ...     ...                 ...                 ...   \n",
       "192          1      0       0 2020-02-07 09:46:38 2020-02-07 09:46:38   \n",
       "193          1      0       0 2020-02-07 10:21:36 2020-02-07 10:21:36   \n",
       "194          1      0       0 2020-02-07 10:21:43 2020-02-07 10:21:43   \n",
       "195          1      3       0 2020-02-07 15:35:24 2020-02-07 15:45:54   \n",
       "196          1      1       0 2020-02-10 16:37:15 2020-02-10 16:38:21   \n",
       "\n",
       "             deleted_at  \n",
       "0   2019-07-29 12:20:08  \n",
       "1   2019-07-29 12:20:16  \n",
       "2   2019-07-29 12:20:25  \n",
       "3   2019-07-29 12:21:40  \n",
       "4   2019-07-29 12:21:47  \n",
       "..                  ...  \n",
       "192                 NaT  \n",
       "193                 NaT  \n",
       "194                 NaT  \n",
       "195                 NaT  \n",
       "196                 NaT  \n",
       "\n",
       "[197 rows x 24 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> adress data normalisation <h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "region=['Tunis','Manouba','ben arous',\n",
    "        'ariana',' Bizerte','beja', 'jandouba', 'nabeul' , 'zaghouane', 'silana', 'kef' ,\n",
    "        'kasserine' , 'kairouane' , 'Sousse' , 'monastir', 'Mahdia' , 'Sfax' , 'sidi' 'bouzid' , 'gafsa' ,\n",
    "        'touzeur', 'kbeli' , 'gabes' , 'mednine' ,'tataouine']\n",
    "region=[x.upper() for x in region]\n",
    "destination_adress= df1['dest_addr'] \n",
    "depart_adress = df1['pickup_addr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def adressNormalisation(col):\n",
    "    i=0\n",
    "    lista=[]\n",
    "    adr=''\n",
    "    for phrase in col:\n",
    "        verif=False\n",
    "        for adrs in region:\n",
    "            if adrs in phrase.upper():\n",
    "                verif=True\n",
    "                adr=adrs\n",
    "        if verif==True :\n",
    "                #lista.append([i,phrase,adr])\n",
    "                lista.append([adr])\n",
    "\n",
    "        else : \n",
    "                #lista.append([i,phrase,random.choice(region)])\n",
    "                lista.append([random.choice(region)])\n",
    "\n",
    "\n",
    "        i=i+1\n",
    "\n",
    "\n",
    "    return pd.DataFrame(lista, columns=['new_'+col.name])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def adressToNan(col):\n",
    "    i=0\n",
    "    lista=[]\n",
    "    adr=''\n",
    "    for phrase in col:\n",
    "        verif=False\n",
    "        for adrs in region:\n",
    "            if adrs in phrase.upper():\n",
    "                verif=True\n",
    "                adr=adrs\n",
    "        if verif==True :\n",
    "                #lista.append([i,phrase,adr])\n",
    "                lista.append([adr])\n",
    "\n",
    "        else : \n",
    "                #lista.append([i,phrase,random.choice(region)])\n",
    "                lista.append([np.nan])\n",
    "\n",
    "\n",
    "        i=i+1\n",
    "\n",
    "\n",
    "    return pd.DataFrame(lista, columns=['new_'+col.name])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['pickup_addr']=adressNormalisation(df1['pickup_addr'])\n",
    "df1['dest_addr']=adressNormalisation(df1['dest_addr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> fill the nan vehicle_id </h1>\n",
    "<h4>this method return a random vihicle_id by adress </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df1\n",
    "def getVihicleByAdress(df2, adress):\n",
    "    df2=df2.dropna(subset=[\"vehicle_id\"])\n",
    "    df2=df2.groupby('pickup_addr')['vehicle_id'].apply(list)\n",
    "    x=list(set(df2[adress]))\n",
    "    return random.choice(x)\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pickup_addr\n",
       "ARIANA                                  [8.0, 8.0, nan, 8.0]\n",
       "BEJA                                            [23.0, 23.0]\n",
       "GABES              [nan, nan, nan, nan, 21.0, nan, nan, nan]\n",
       "MANOUBA                                                [5.0]\n",
       "SFAX       [nan, 9.0, nan, nan, nan, 10.0, nan, 10.0, 9.0...\n",
       "SOUSSE     [nan, nan, nan, 25.0, 21.0, nan, 21.0, 22.0, n...\n",
       "TUNIS      [nan, 7.0, 3.0, 7.0, nan, nan, nan, 13.0, nan,...\n",
       "Name: vehicle_id, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.groupby('pickup_addr')['vehicle_id'].apply(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\meher\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:670: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(df1['vehicle_id'])):\n",
    "    if np.isnan(df1['vehicle_id'].iloc[i]):\n",
    "        df1['vehicle_id'].iloc[i]=getVihicleByAdress(df1,df1['pickup_addr'].iloc[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> prepare train and test data </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vihicule_id=df1['vehicle_id'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['Datetime'] = df1['date_time']\n",
    "for i in range(len(df1)):\n",
    "    \n",
    "    df['Year'] = df.Datetime.dt.year\n",
    "    df['Month'] = df.Datetime.dt.month\n",
    "    df['Day'] = df.Datetime.dt.day\n",
    "    df['Hour'] = df.Datetime.dt.hour\n",
    "    #df['Minute'] = df.Datetime.dt.minute\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df1[['dest_addr','pickup_addr']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=pd.concat([df[['Year','Day','Month','Hour']],df1['vehicle_id']],sort=False,axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.15, random_state=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>train model</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the score of LR  is : 0.26666666666666666 \n",
      "the score of LDA  is : 0.16666666666666666 \n",
      "the score of KNN  is : 0.4 \n",
      "the score of CART  is : 0.43333333333333335 \n",
      "the score of NB  is : 0.13333333333333333 \n",
      "the score of SVM  is : 0.06666666666666667 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\meher\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\meher\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Compare Algorithms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "# load dataset\n",
    "\n",
    "# prepare configuration for cross validation test harness\n",
    "seed = 7\n",
    "# prepare models\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression()))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVM', SVC()))\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "scores = []\n",
    "scoring = 'accuracy'\n",
    "\n",
    "for name, model in models:\n",
    "  \n",
    "    cv_results = MultiOutputClassifier(model).fit(x_train,y_train)\n",
    "   \n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"the score of %s  is : %s \" % (name, cv_results.score(x_test,y_test))\n",
    "    scores.append(cv_results.score(x_test,y_test))\n",
    "    print(msg)\n",
    "# boxplot algorithm comparison\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(model):\n",
    "    models = {\n",
    "        'LR': 0,\n",
    "        'LDA': 1,\n",
    "        'KNN': 2,\n",
    "        \"DT\": 3,\n",
    "        'GNB': 4,\n",
    "        'SVM': 5,\n",
    "    }\n",
    "    return (models.get(model, \"Invalid model\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import mysql.connector\n",
    "from mysql.connector import Error\n",
    "\n",
    "def get_vehicle(ids,model_name):\n",
    "\n",
    "    try:\n",
    "        connection = mysql.connector.connect(host='localhost',\n",
    "                                         database='optimatets',\n",
    "                                         user='root',\n",
    "                                         password='')\n",
    "        records=[]  \n",
    "        sql_select_Query=[]\n",
    "        vihicle=[]\n",
    "        for i in ids:        \n",
    "            reqet = \"SELECT department_id,company_id,make,model,type_id FROM vehicles WHERE id='\" + str(i) + \"';\"\n",
    "            sql_select_Query.append(reqet)\n",
    "       \n",
    "        for req in sql_select_Query:\n",
    "            cursor = connection.cursor()\n",
    "            cursor.execute(req)\n",
    "            ex=cursor.fetchall()[0]\n",
    "            msg=\"this vihicle of the company : \"+str(ex[1])+\" , departement : \"+str(ex[0]) +\" with the make : \"+ ex[2]+\" and a model : \"+ex[3]\n",
    "            records.append(ex)    \n",
    "            vihicle.append({'message':msg,'type_id':ex[4],\"score\":scores[get_model(model_name)]})\n",
    "    except Error as e:\n",
    "        print(\"Error reading data from MySQL table\", e)\n",
    "    finally:\n",
    "        if (connection.is_connected()):\n",
    "            connection.close()\n",
    "            cursor.close()\n",
    "            print(\"MySQL connection is closed\")\n",
    "    \n",
    "    return(vihicle)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [14/Sep/2020 08:51:39] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'date': '2020-12-11T08:15', 'retour': 'tunis', 'destination': 'sousse', 'model': 'KNN'}\n",
      "   destination  pickup  Year Day Month  Hour    id\n",
      "0         SFAX  SOUSSE  2020  11    12     8  21.0\n",
      "1        TUNIS   TUNIS  2020  11    12     8   7.0\n",
      "2        TUNIS   TUNIS  2020  11    12     8   3.0\n",
      "3        TUNIS    SFAX  2020  11    12     8   9.0\n",
      "4        TUNIS    SFAX  2020  11    12     8  10.0\n",
      "5        TUNIS    SFAX  2020  11    12     8  11.0\n",
      "6         SFAX  SOUSSE  2020  11    12     8  16.0\n",
      "7        TUNIS    SFAX  2020  11    12     8  13.0\n",
      "8         SFAX   TUNIS  2020  11    12     8  52.0\n",
      "9         SFAX  SOUSSE  2020  11    12     8  18.0\n",
      "10        SFAX   TUNIS  2020  11    12     8  51.0\n",
      "11        SFAX  SOUSSE  2020  11    12     8  19.0\n",
      "12        SFAX  SOUSSE  2020  11    12     8  17.0\n",
      "13        SFAX   TUNIS  2020  11    12     8  46.0\n",
      "14       TUNIS   TUNIS  2020  11    12     8   5.0\n",
      "15        SFAX  SOUSSE  2020  11    12     8  23.0\n",
      "16        SFAX  SOUSSE  2020  11    12     8  20.0\n",
      "17        SFAX  SOUSSE  2020  11    12     8  25.0\n",
      "18        SFAX  SOUSSE  2020  11    12     8  22.0\n",
      "19       TUNIS    SFAX  2020  11    12     8   8.0\n",
      "Empty DataFrame\n",
      "Columns: [destination, pickup, Year, Day, Month, Hour, id]\n",
      "Index: []\n",
      "[{'message': 'there is no vehicles , please change the time or pickup/destination', 'type_id': -1, 'score': 0.4}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [14/Sep/2020 08:52:19] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MySQL connection is closed\n",
      "{'date': '2020-12-11T08:15', 'retour': 'tunis', 'destination': 'sfax', 'model': 'KNN'}\n",
      "   destination  pickup  Year Day Month  Hour    id\n",
      "0         SFAX  SOUSSE  2020  11    12     8  21.0\n",
      "1        TUNIS   TUNIS  2020  11    12     8   7.0\n",
      "2        TUNIS   TUNIS  2020  11    12     8   3.0\n",
      "3        TUNIS    SFAX  2020  11    12     8   9.0\n",
      "4        TUNIS    SFAX  2020  11    12     8  10.0\n",
      "5        TUNIS    SFAX  2020  11    12     8  11.0\n",
      "6         SFAX  SOUSSE  2020  11    12     8  16.0\n",
      "7        TUNIS    SFAX  2020  11    12     8  13.0\n",
      "8         SFAX   TUNIS  2020  11    12     8  52.0\n",
      "9         SFAX  SOUSSE  2020  11    12     8  18.0\n",
      "10        SFAX   TUNIS  2020  11    12     8  51.0\n",
      "11        SFAX  SOUSSE  2020  11    12     8  19.0\n",
      "12        SFAX  SOUSSE  2020  11    12     8  17.0\n",
      "13        SFAX   TUNIS  2020  11    12     8  46.0\n",
      "14       TUNIS   TUNIS  2020  11    12     8   5.0\n",
      "15        SFAX  SOUSSE  2020  11    12     8  23.0\n",
      "16        SFAX  SOUSSE  2020  11    12     8  20.0\n",
      "17        SFAX  SOUSSE  2020  11    12     8  25.0\n",
      "18        SFAX  SOUSSE  2020  11    12     8  22.0\n",
      "19       TUNIS    SFAX  2020  11    12     8   8.0\n",
      "   destination pickup  Year Day Month  Hour    id\n",
      "8         SFAX  TUNIS  2020  11    12     8  52.0\n",
      "10        SFAX  TUNIS  2020  11    12     8  51.0\n",
      "13        SFAX  TUNIS  2020  11    12     8  46.0\n",
      "[{'message': 'this vihicle of the company : 13 , departement : 9 with the make : Toyota and a model : Truck', 'type_id': 1, 'score': 0.4}, {'message': 'this vihicle of the company : 56 , departement : None with the make : IVECO and a model : 35J11', 'type_id': 1, 'score': 0.4}, {'message': 'this vihicle of the company : 47 , departement : None with the make : MERCEDES and a model : DAIMLER BENZ', 'type_id': 1, 'score': 0.4}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-09-14 08:53:06,952] ERROR in app: Exception on / [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\meher\\anaconda3\\lib\\site-packages\\flask\\app.py\", line 2446, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"C:\\Users\\meher\\anaconda3\\lib\\site-packages\\flask\\app.py\", line 1951, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"C:\\Users\\meher\\anaconda3\\lib\\site-packages\\flask\\app.py\", line 1820, in handle_user_exception\n",
      "    reraise(exc_type, exc_value, tb)\n",
      "  File \"C:\\Users\\meher\\anaconda3\\lib\\site-packages\\flask\\_compat.py\", line 39, in reraise\n",
      "    raise value\n",
      "  File \"C:\\Users\\meher\\anaconda3\\lib\\site-packages\\flask\\app.py\", line 1949, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"C:\\Users\\meher\\anaconda3\\lib\\site-packages\\flask\\app.py\", line 1935, in dispatch_request\n",
      "    return self.view_functions[rule.endpoint](**req.view_args)\n",
      "  File \"<ipython-input-24-9bee8f2a70a1>\", line 8, in index\n",
      "    date=d['date'].split(\"T\")\n",
      "KeyError: 'date'\n",
      "127.0.0.1 - - [14/Sep/2020 08:53:06] \"\u001b[35m\u001b[1mPOST / HTTP/1.1\u001b[0m\" 500 -\n",
      "[2020-09-14 08:58:10,993] ERROR in app: Exception on / [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\meher\\anaconda3\\lib\\site-packages\\flask\\app.py\", line 2446, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"C:\\Users\\meher\\anaconda3\\lib\\site-packages\\flask\\app.py\", line 1951, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"C:\\Users\\meher\\anaconda3\\lib\\site-packages\\flask\\app.py\", line 1820, in handle_user_exception\n",
      "    reraise(exc_type, exc_value, tb)\n",
      "  File \"C:\\Users\\meher\\anaconda3\\lib\\site-packages\\flask\\_compat.py\", line 39, in reraise\n",
      "    raise value\n",
      "  File \"C:\\Users\\meher\\anaconda3\\lib\\site-packages\\flask\\app.py\", line 1949, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"C:\\Users\\meher\\anaconda3\\lib\\site-packages\\flask\\app.py\", line 1935, in dispatch_request\n",
      "    return self.view_functions[rule.endpoint](**req.view_args)\n",
      "  File \"<ipython-input-24-9bee8f2a70a1>\", line 10, in index\n",
      "    hours=date[1].split(':')\n",
      "IndexError: list index out of range\n",
      "127.0.0.1 - - [14/Sep/2020 08:58:10] \"\u001b[35m\u001b[1mPOST / HTTP/1.1\u001b[0m\" 500 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, make_response\n",
    "import json\n",
    "app = Flask(__name__)\n",
    "@app.route('/', methods=['POST'])\n",
    "def index():\n",
    "    \n",
    "    d = request.form.to_dict() # data recived from form\n",
    "    date=d['date'].split(\"T\")\n",
    "    date1=date[0].split(\"-\")\n",
    "    hours=date[1].split(':')\n",
    "    date2=list(map(int, date1)) \n",
    "    hours2= list(map(int, hours)) \n",
    "   \n",
    "    \n",
    "    df=pd.DataFrame(columns=['Datatime'],data=np.array(range(len(vihicule_id))))\n",
    "   \n",
    "    for i in range(len(vihicule_id)):  \n",
    "    \n",
    "        df['Year'] =date1[0]\n",
    "        df['Month'] =date1[1]\n",
    "        df['Day'] = date1[2]\n",
    "        df['Hour'] =int(hours[0])\n",
    "        \n",
    "        \n",
    "    \n",
    "\n",
    "    xx=pd.concat([df[['Year','Day','Month','Hour']],pd.Series(vihicule_id).rename(\"id\")],sort=False,axis=1) #input data\n",
    "    result=pd.concat([pd.DataFrame(results[get_model(d['model'])].predict(np.array(xx))),xx],sort=False,axis=1)                 #result of prediction\n",
    "    result=result.rename(columns={0: 'destination',1:'pickup'})\n",
    "    ms=result[(result.destination == str( d['destination']).upper()) & (result.pickup == str(d['retour']).upper())] # return only the result of our destination and pickup\n",
    "        \n",
    "    if ms.empty:\n",
    "        vehicles=[{'message': 'there is no vehicles , please change the time or pickup/destination','type_id': -1,'score':scores[get_model(d['model'])]}]\n",
    "    else:\n",
    "        \n",
    "        vehicles= get_vehicle(ms['id'].tolist(),d['model'])       # return the data of vehicles predicted                                                \n",
    "    \n",
    "    \n",
    "   \n",
    "    \n",
    "   \n",
    "    \n",
    "    print(d)        # data recived from form\n",
    "    print(result)    # result of the prediction of all vehicles\n",
    "    print(ms)        # result of the prediction of  vehicle who strat of our pickup and go to destination\n",
    "    print(vehicles) # the data of vehicle predicted\n",
    "    \n",
    "    \n",
    "    data=make_response(json.dumps(vehicles)) # transform final result to json\n",
    "    resp=data\n",
    "    resp.status_code = 200\n",
    "    resp.headers['Access-Control-Allow-Origin'] = '*' # configiration \n",
    "    return resp\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    app.run()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
