{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import datetime\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> get data from database</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MySQL connection is closed\n"
     ]
    }
   ],
   "source": [
    "import mysql.connector\n",
    "from mysql.connector import Error\n",
    "records=[]\n",
    "try:\n",
    "    connection = mysql.connector.connect(host='localhost',\n",
    "                                         database='optimatets',\n",
    "                                         user='root',\n",
    "                                         password='')\n",
    "    sql_select_Query=[]\n",
    "    sql_select_Query.append( \"select * from bookings\")\n",
    "    sql_select_Query.append(\"select * from driver_vehicle\")\n",
    "    sql_select_Query.append(\"select * from tracking\")\n",
    "    sql_select_Query.append(\"select * from vehicles\")\n",
    "    sql_select_Query.append(\"select * from vehicle_types\")\n",
    "    for req in sql_select_Query:\n",
    "        cursor = connection.cursor()\n",
    "        cursor.execute(req)\n",
    "        records.append( cursor.fetchall())    \n",
    "\n",
    "except Error as e:\n",
    "    print(\"Error reading data from MySQL table\", e)\n",
    "finally:\n",
    "    if (connection.is_connected()):\n",
    "        connection.close()\n",
    "        cursor.close()\n",
    "        print(\"MySQL connection is closed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>book_type</th>\n",
       "      <th>promo_id</th>\n",
       "      <th>type_id</th>\n",
       "      <th>accept_status</th>\n",
       "      <th>total_weight</th>\n",
       "      <th>company_id</th>\n",
       "      <th>date_time</th>\n",
       "      <th>user_id</th>\n",
       "      <th>vehicle_id</th>\n",
       "      <th>...</th>\n",
       "      <th>duration</th>\n",
       "      <th>pickup_addr</th>\n",
       "      <th>dest_addr</th>\n",
       "      <th>note</th>\n",
       "      <th>travellers</th>\n",
       "      <th>status</th>\n",
       "      <th>payment</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>deleted_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>s</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "      <td>53</td>\n",
       "      <td>30.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2019-07-03 12:01:13</td>\n",
       "      <td>53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>Tunis, Tunisia</td>\n",
       "      <td>Sousse, Tunisia</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-07-01 11:02:24</td>\n",
       "      <td>2019-07-29 12:20:08</td>\n",
       "      <td>2019-07-29 12:20:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>s</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "      <td>53</td>\n",
       "      <td>20.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2019-07-06 07:09:11</td>\n",
       "      <td>53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>Cafe Karawen, Route Gremda, Sfax, Tunisia</td>\n",
       "      <td>Avenue De Carthage, Tunisia</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-07-04 14:13:04</td>\n",
       "      <td>2019-07-29 12:20:16</td>\n",
       "      <td>2019-07-29 12:20:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>s</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>60</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2019-07-08 08:21:49</td>\n",
       "      <td>60</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>tunis, Tunisie</td>\n",
       "      <td>Bizerte Centre, Rue Mohamed Ali, Bizerte, Tunisia</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-07-04 14:23:12</td>\n",
       "      <td>2019-07-29 12:20:25</td>\n",
       "      <td>2019-07-29 12:20:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>s</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>51</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2019-07-11 09:06:34</td>\n",
       "      <td>51</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>Avenue De Carthage, Tunisie</td>\n",
       "      <td>Sahloul, Sousse, Tunisie</td>\n",
       "      <td>Bien reçu. Je note çà appele moi sur 22222222</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-07-09 11:08:28</td>\n",
       "      <td>2019-07-29 12:21:40</td>\n",
       "      <td>2019-07-29 12:21:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>s</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "      <td>60</td>\n",
       "      <td>25.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2019-07-14 12:24:05</td>\n",
       "      <td>60</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>Bizerte, Tunisie</td>\n",
       "      <td>Mahdia, Tunisie</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-07-09 11:24:51</td>\n",
       "      <td>2019-07-29 12:21:47</td>\n",
       "      <td>2019-07-29 12:21:47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id book_type  promo_id  type_id  accept_status  total_weight  company_id  \\\n",
       "0   4         s       NaN       17             53          30.0        11.0   \n",
       "1   8         s       NaN       17             53          20.0        11.0   \n",
       "2   9         s       NaN        6             60          10.0        11.0   \n",
       "3  14         s       NaN        3             51           5.0        10.0   \n",
       "4  15         s       NaN       17             60          25.0        11.0   \n",
       "\n",
       "            date_time  user_id  vehicle_id         ...          duration  \\\n",
       "0 2019-07-03 12:01:13       53         NaN         ...              None   \n",
       "1 2019-07-06 07:09:11       53         NaN         ...              None   \n",
       "2 2019-07-08 08:21:49       60         7.0         ...              None   \n",
       "3 2019-07-11 09:06:34       51         3.0         ...              None   \n",
       "4 2019-07-14 12:24:05       60         7.0         ...              None   \n",
       "\n",
       "                                 pickup_addr  \\\n",
       "0                             Tunis, Tunisia   \n",
       "1  Cafe Karawen, Route Gremda, Sfax, Tunisia   \n",
       "2                             tunis, Tunisie   \n",
       "3                Avenue De Carthage, Tunisie   \n",
       "4                           Bizerte, Tunisie   \n",
       "\n",
       "                                           dest_addr  \\\n",
       "0                                    Sousse, Tunisia   \n",
       "1                        Avenue De Carthage, Tunisia   \n",
       "2  Bizerte Centre, Rue Mohamed Ali, Bizerte, Tunisia   \n",
       "3                           Sahloul, Sousse, Tunisie   \n",
       "4                                    Mahdia, Tunisie   \n",
       "\n",
       "                                            note travellers status payment  \\\n",
       "0                                           None          1      0       0   \n",
       "1                                           None          1      0       0   \n",
       "2                                           None          1      0       0   \n",
       "3  Bien reçu. Je note çà appele moi sur 22222222          1      3       1   \n",
       "4                                           None          1      1       0   \n",
       "\n",
       "           created_at          updated_at          deleted_at  \n",
       "0 2019-07-01 11:02:24 2019-07-29 12:20:08 2019-07-29 12:20:08  \n",
       "1 2019-07-04 14:13:04 2019-07-29 12:20:16 2019-07-29 12:20:16  \n",
       "2 2019-07-04 14:23:12 2019-07-29 12:20:25 2019-07-29 12:20:25  \n",
       "3 2019-07-09 11:08:28 2019-07-29 12:21:40 2019-07-29 12:21:40  \n",
       "4 2019-07-09 11:24:51 2019-07-29 12:21:47 2019-07-29 12:21:47  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bookings=pd.DataFrame(records[0],columns=['id', 'book_type', 'promo_id' , 'type_id' , 'accept_status', 'total_weight', 'company_id', 'date_time', 'user_id', 'vehicle_id', 'driver_id', 'customer_id', 'pickup', 'dropoff', 'duration', 'pickup_addr', 'dest_addr','note', 'travellers', 'status', 'payment', 'created_at', 'updated_at', 'deleted_at'])\n",
    "bookings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(197, 24)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1=bookings\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>add some data to data base </h1>\n",
    "<h4>to improve the model we added some random rows . so , we picked a random row and we changeed the date  </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  maxDate(df):\n",
    "    lista=[]\n",
    "    for i in range(len(df['date_time'])):\n",
    "        lista.append(datetime.timestamp(df['date_time'][i]))\n",
    "    return max(lista)\n",
    "\n",
    "def addRow(df1,date_time):\n",
    "    row = df1.sample()\n",
    "    row['date_time']=date_time\n",
    "    df1=df1.append(row)\n",
    "    return df1\n",
    "            \n",
    "\n",
    "def fillDatabase(df1):\n",
    "    now = datetime.timestamp(datetime.now())\n",
    "    max_date=maxDate(df1)+ 76522\n",
    "    day = max_date\n",
    "    cpt=0\n",
    "    while now> day :\n",
    "        day=day+86400\n",
    "        max_date=day+random.randint(39600,86339)\n",
    "        df1=addRow(df1,datetime.fromtimestamp(max_date))\n",
    "        cpt=cpt+1\n",
    "        \n",
    "        for i in range(random.randint(0,5)):\n",
    "            max_date=day+random.randint(21600,39600)\n",
    "            #print(datetime.fromtimestamp(max_date))\n",
    "            df1=addRow(df1,datetime.fromtimestamp(max_date))\n",
    "            cpt=cpt+1\n",
    "            \n",
    "            for j in range(random.randint(0,3)):\n",
    "                max_date=day+random.randint(0,21600)\n",
    "                #print(datetime.fromtimestamp(max_date))\n",
    "                df1=addRow(df1,datetime.fromtimestamp(max_date))\n",
    "                cpt=cpt+1\n",
    "                \n",
    "    print(cpt ,\"rows added !\")        \n",
    "   \n",
    "                    \n",
    "                \n",
    "       \n",
    "    return df1\n",
    "   \n",
    "   \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "657 rows added !\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(854, 24)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1=fillDatabase(df1)  \n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> adress data normalisation <h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "region=['Tunis','Manouba','ben arous',\n",
    "        'ariana',' Bizerte','beja', 'jandouba', 'nabeul' , 'zaghouane', 'silana', 'kef' ,\n",
    "        'kasserine' , 'kairouane' , 'Sousse' , 'monastir', 'Mahdia' , 'Sfax' , 'sidi' 'bouzid' , 'gafsa' ,\n",
    "        'touzeur', 'kbeli' , 'gabes' , 'mednine' ,'tataouine']\n",
    "region=[x.upper() for x in region]\n",
    "destination_adress= df1['dest_addr'] \n",
    "depart_adress = df1['pickup_addr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def adressNormalisation(col):\n",
    "    i=0\n",
    "    lista=[]\n",
    "    adr=''\n",
    "    for phrase in col:\n",
    "        verif=False\n",
    "        for adrs in region:\n",
    "            if adrs in phrase.upper():\n",
    "                verif=True\n",
    "                adr=adrs\n",
    "        if verif==True :\n",
    "                #lista.append([i,phrase,adr])\n",
    "                lista.append([adr])\n",
    "\n",
    "        else : \n",
    "                #lista.append([i,phrase,random.choice(region)])\n",
    "                lista.append([random.choice(region)])\n",
    "\n",
    "\n",
    "        i=i+1\n",
    "\n",
    "\n",
    "    return pd.DataFrame(lista, columns=['new_'+col.name])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def adressToNan(col):\n",
    "    i=0\n",
    "    lista=[]\n",
    "    adr=''\n",
    "    for phrase in col:\n",
    "        verif=False\n",
    "        for adrs in region:\n",
    "            if adrs in phrase.upper():\n",
    "                verif=True\n",
    "                adr=adrs\n",
    "        if verif==True :\n",
    "                #lista.append([i,phrase,adr])\n",
    "                lista.append([adr])\n",
    "\n",
    "        else : \n",
    "                #lista.append([i,phrase,random.choice(region)])\n",
    "                lista.append([np.nan])\n",
    "\n",
    "\n",
    "        i=i+1\n",
    "\n",
    "\n",
    "    return pd.DataFrame(lista, columns=['new_'+col.name])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['pickup_addr']=adressNormalisation(df1['pickup_addr'])\n",
    "df1['dest_addr']=adressNormalisation(df1['dest_addr'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> fill the nan vehicle_id </h1>\n",
    "<h4>this method return a random vihicle_id by adress </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2=df1\n",
    "def getVihicleByAdress(df2, adress):\n",
    "    df2=df2.dropna(subset=[\"vehicle_id\"])\n",
    "    df2=df2.groupby('pickup_addr')['vehicle_id'].apply(list)\n",
    "    x=list(set(df2[adress]))\n",
    "    return random.choice(x)\n",
    " \n",
    "getVihicleByAdress(df2,'SFAX')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pickup_addr\n",
       "ARIANA     [8.0, 8.0, nan, 8.0, 8.0, 8.0, nan, 8.0, 8.0, ...\n",
       "BEJA       [23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23....\n",
       "GABES      [nan, nan, nan, nan, 21.0, nan, nan, nan, nan,...\n",
       "MANOUBA                                                [5.0]\n",
       "SFAX       [nan, 9.0, nan, nan, nan, 10.0, nan, 10.0, 9.0...\n",
       "SOUSSE     [nan, nan, nan, 25.0, 21.0, nan, 21.0, 22.0, n...\n",
       "TUNIS      [nan, 7.0, 3.0, 7.0, nan, nan, nan, 13.0, nan,...\n",
       "Name: vehicle_id, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.groupby('pickup_addr')['vehicle_id'].apply(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:189: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(df1['vehicle_id'])):\n",
    "    if np.isnan(df1['vehicle_id'].iloc[i]):\n",
    "        df1['vehicle_id'].iloc[i]=getVihicleByAdress(df1,df1['pickup_addr'].iloc[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> prepare train and test data </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20., 21.,  7.,  3.,  9., 19., 51., 10., 52., 13., 18., 16., 11.,\n",
       "       17., 23., 46.,  5., 25., 22.,  8.])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vihicule_id=df1['vehicle_id'].unique()\n",
    "vihicule_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['Datetime'] = df1['date_time']\n",
    "for i in range(len(df1)):\n",
    "    \n",
    "    df['Year'] = df.Datetime.dt.year\n",
    "    df['Month'] = df.Datetime.dt.month\n",
    "    df['Day'] = df.Datetime.dt.day\n",
    "    df['Hour'] = df.Datetime.dt.hour\n",
    "    #df['Minute'] = df.Datetime.dt.minute\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(854, 24)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df1[['dest_addr','pickup_addr']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=pd.concat([df[['Year','Day','Month','Hour']],df1['vehicle_id']],sort=False,axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(854, 5)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.15, random_state=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>train model</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR   : 0.06201550387596899 \n",
      "LDA   : 0.06201550387596899 \n",
      "KNN   : 0.3178294573643411 \n",
      "CART   : 0.43410852713178294 \n",
      "NB   : 0.20930232558139536 \n",
      "SVM   : 0.32558139534883723 \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Compare Algorithms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "# load dataset\n",
    "\n",
    "# prepare configuration for cross validation test harness\n",
    "seed = 7\n",
    "# prepare models\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression()))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVM', SVC()))\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "scoring = 'accuracy'\n",
    "for name, model in models:\n",
    "  \n",
    "    cv_results = MultiOutputClassifier(model).fit(x_train,y_train)\n",
    "   \n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s   : %s \" % (name, cv_results.score(x_test,y_test))\n",
    "    print(msg)\n",
    "# boxplot algorithm comparison\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MySQL connection is closed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'message': 'this vihicle of the company : 10 , departement : 3 with the make : Scania and a model : Y6',\n",
       "  'type_id': 17},\n",
       " {'message': 'this vihicle of the company : 11 , departement : 4 with the make : Peugeot and a model : 3008',\n",
       "  'type_id': 6},\n",
       " {'message': 'this vihicle of the company : 11 , departement : 4 with the make : Renault and a model : Piagio',\n",
       "  'type_id': 17}]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "def get_vehicle(ids):\n",
    "\n",
    "    try:\n",
    "        connection = mysql.connector.connect(host='localhost',\n",
    "                                         database='optimatets',\n",
    "                                         user='root',\n",
    "                                         password='')\n",
    "        records=[]  \n",
    "        sql_select_Query=[]\n",
    "        vihicle=[]\n",
    "        for i in ids:        \n",
    "            reqet = \"SELECT department_id,company_id,make,model,type_id FROM vehicles WHERE id='\" + str(i) + \"';\"\n",
    "            sql_select_Query.append(reqet)\n",
    "       \n",
    "        for req in sql_select_Query:\n",
    "            cursor = connection.cursor()\n",
    "            cursor.execute(req)\n",
    "            ex=cursor.fetchall()[0]\n",
    "            msg=\"this vihicle of the company : \"+str(ex[1])+\" , departement : \"+str(ex[0]) +\" with the make : \"+ ex[2]+\" and a model : \"+ex[3]\n",
    "            records.append(ex)    \n",
    "            vihicle.append({'message':msg,'type_id':ex[4]})\n",
    "    except Error as e:\n",
    "        print(\"Error reading data from MySQL table\", e)\n",
    "    finally:\n",
    "        if (connection.is_connected()):\n",
    "            connection.close()\n",
    "            cursor.close()\n",
    "            print(\"MySQL connection is closed\")\n",
    "    \n",
    "    return(vihicle)\n",
    "get_vehicle([4,7,5])       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: Do not use the development server in a production environment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [24/May/2020 21:45:25] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'date': '2020-11-12T09:05', 'retour': 'gabes', 'destination': 'mahdia'}\n",
      "   destination  pickup  Year Day Month  Hour    id\n",
      "0         SFAX   TUNIS  2020  12    11     9  20.0\n",
      "1         SFAX    SFAX  2020  12    11     9  21.0\n",
      "2         SFAX   TUNIS  2020  12    11     9   7.0\n",
      "3         SFAX   TUNIS  2020  12    11     9   3.0\n",
      "4        TUNIS    SFAX  2020  12    11     9   9.0\n",
      "5        TUNIS    SFAX  2020  12    11     9  19.0\n",
      "6         SFAX   TUNIS  2020  12    11     9  51.0\n",
      "7        TUNIS    SFAX  2020  12    11     9  10.0\n",
      "8        GABES   TUNIS  2020  12    11     9  52.0\n",
      "9         SFAX   TUNIS  2020  12    11     9  13.0\n",
      "10        SFAX   TUNIS  2020  12    11     9  18.0\n",
      "11        SFAX   TUNIS  2020  12    11     9  16.0\n",
      "12        SFAX   TUNIS  2020  12    11     9  11.0\n",
      "13        SFAX   TUNIS  2020  12    11     9  17.0\n",
      "14   KASSERINE    BEJA  2020  12    11     9  23.0\n",
      "15        SFAX   TUNIS  2020  12    11     9  46.0\n",
      "16        SFAX   TUNIS  2020  12    11     9   5.0\n",
      "17       TUNIS  SOUSSE  2020  12    11     9  25.0\n",
      "18      ARIANA  SOUSSE  2020  12    11     9  22.0\n",
      "19        SFAX  ARIANA  2020  12    11     9   8.0\n",
      "Empty DataFrame\n",
      "Columns: [destination, pickup, Year, Day, Month, Hour, id]\n",
      "Index: []\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, make_response\n",
    "import json\n",
    "app = Flask(__name__)\n",
    "@app.route('/', methods=['POST'])\n",
    "def index():\n",
    "    \n",
    "    #ms=str({{\"hello\":\"word\"},{\"hello\":\"meher\"}})\n",
    "    d = request.form.to_dict() # data recived from form\n",
    "    date=d['date'].split(\"T\")\n",
    "    date1=date[0].split(\"-\")\n",
    "    hours=date[1].split(':')\n",
    "    date2=list(map(int, date1)) \n",
    "    hours2= list(map(int, hours)) \n",
    "   \n",
    "    \n",
    "    df=pd.DataFrame(columns=['Datatime'],data=np.array(range(len(vihicule_id))))\n",
    "   \n",
    "    for i in range(len(vihicule_id)):  \n",
    "    \n",
    "        df['Year'] =date1[0]\n",
    "        df['Month'] =date1[1]\n",
    "        df['Day'] = date1[2]\n",
    "        df['Hour'] =int(hours[0])\n",
    "        \n",
    "        \n",
    "   \n",
    "    xx=pd.concat([df[['Year','Day','Month','Hour']],pd.Series(vihicule_id).rename(\"id\")],sort=False,axis=1) #input data\n",
    "    result=pd.concat([pd.DataFrame(results[3].predict(np.array(xx))),xx],sort=False,axis=1)                 #result of prediction\n",
    "    result=result.rename(columns={0: 'destination',1:'pickup'})\n",
    "    ms=result[(result.destination == str( d['destination']).upper()) & (result.pickup == str(d['retour']).upper())] # return only the result of our destination and pickup\n",
    "    if ms.empty:\n",
    "        vehicles=[]                                              \n",
    "    else :\n",
    "        vehicles= get_vehicle(ms['id'].tolist())       # return the data of vehicles predicted  \n",
    "        \n",
    "    \n",
    "   \n",
    "    \n",
    "   \n",
    "    \n",
    "    print(d)        # data recived from form\n",
    "    print(result)    # result of the prediction of all vehicles\n",
    "    print(ms)        # result of the prediction of  vehicle who strat of our pickup and go to destination\n",
    "    print(vehicles) # the data of vehicle predicted\n",
    "    \n",
    "    if vehicles:\n",
    "        data=make_response(json.dumps(vehicles)) # transform final result to json\n",
    "    else:\n",
    "        data=data=make_response(json.dumps([{'message': 'we have not a vehicle in this time . please change the date , pickup or destination', 'type_id': 7}]))\n",
    "    resp=data\n",
    "    resp.status_code = 200\n",
    "    resp.headers['Access-Control-Allow-Origin'] = '*' # configiration \n",
    "    return resp\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    app.run()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
