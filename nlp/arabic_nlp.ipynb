{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import script\n",
    "import sys\n",
    "import re\n",
    "import io\n",
    "def break_into_sentences(input_file,output):\n",
    "    f = io.open(input_file, 'r', encoding='utf8')\n",
    "    Sentence_Size = 0\n",
    "    Max_Size = 40  # Max_Size od the sentences\n",
    "    paragraph = f.read()\n",
    "\t#remove_diacritics fct\n",
    "    regex = re.compile(r'[\\u064B\\u064C\\u064D\\u064E\\u064F\\u0650\\u0651\\u0652]')\n",
    "    paragraph = re.sub(regex, '', paragraph)\n",
    "    #remove_urls fct\n",
    "    regex = re.compile(r\"(http|https|ftp)://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+\")\n",
    "    paragraph = re.sub(regex, '', paragraph)\n",
    "    regex = re.compile(r\"(\\d|[\\u0660\\u0661\\u0662\\u0663\\u0664\\u0665\\u0666\\u0667\\u0668\\u0669])+\")\n",
    "    paragraph = re.sub(regex, '', paragraph)\n",
    "\t#remove one_character words\n",
    "    regex = re.compile(r'\\s.\\s')\n",
    "    paragraph = re.sub(regex, ' ', paragraph)\n",
    "    resultFile = io.open(output, 'w',encoding='utf8')\n",
    "    sentences = list()\n",
    "    temp_sentence = list()\n",
    "    flag = False\n",
    "    for ch in paragraph.strip():\n",
    "        if ch in [u'؟', u'!', u'.', u':', u'؛',u'?']:\n",
    "            Sentence_Size = 0\n",
    "            flag = True\n",
    "        elif flag:\n",
    "            sentences.append(''.join(temp_sentence).strip())\n",
    "            temp_sentence = []\n",
    "            flag = False\n",
    "        regex = re.compile(r'[إأٱآا]')\n",
    "        ch = re.sub(regex, 'ا', ch)\n",
    "        regex = re.compile(r'[ئ]')\n",
    "        ch = re.sub(regex, 'ى', ch)\n",
    "        #remove_non_arabic_symbols fct\n",
    "        ch = re.sub(r'[^\\u0600-\\u06FF]', ' ', ch)\t\t\n",
    "        temp_sentence.append(ch)\n",
    "        if ch.isspace():\n",
    "           Sentence_Size = Sentence_Size + 1\n",
    "           if Sentence_Size > Max_Size:\n",
    "              Sentence_Size = 0\n",
    "              flag = True\n",
    "              \n",
    "    else:\n",
    "        sentences.append(''.join(temp_sentence).strip())\n",
    "        for item in sentences:\n",
    "            resultFile.write(\"%s\\n\" % re.sub(' +', ' ', item))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "break_into_sentences('input.txt',\"input_segmented\")\n",
    "break_into_sentences('text_resume.txt',\"text_resume_segmented.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open(\"input_segmented\", \"r\" , encoding=\"utf8\")\n",
    "input_segmented = f.read()\n",
    "f=open(\"text_resume_segmented.txt\", \"r\" , encoding=\"utf8\")\n",
    "resume_segmented = f.read()\n",
    "f=open(\"titles.txt\", \"r\" , encoding=\"utf8\")\n",
    "titles = f.read()\n",
    "f=open(\"bonus.txt\", \"r\" , encoding=\"utf8\")\n",
    "bonus = f.read()\n",
    "f=open(\"anapho.txt\", \"r\" , encoding=\"utf8\")\n",
    "anapho = f.read()\n",
    "f=open(\"stigma.txt\", \"r\" , encoding=\"utf8\")\n",
    "sigma = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def label(phrase):\n",
    "    l={}\n",
    "    resumes=resume_segmented.split(\"\\n\")\n",
    "    if phrase in resumes:\n",
    "        l[phrase]= 1\n",
    "    else:\n",
    "        l[phrase]= 0\n",
    "    return l\n",
    "   \n",
    "def PositionPhTexte(phrase):\n",
    "    l= {}\n",
    "    if(input_segmented.index(phrase)+1)<=math.ceil(len(input_segmented)*1/3):\n",
    "        l[phrase]=1\n",
    "    elif(input_segmented.index(phrase)+1)<=math.ceil(len(input_segmented)*2/3):\n",
    "        l[phrase]=2\n",
    "    else:\n",
    "        l[phrase]=3\n",
    "    return l\n",
    "def Nb_mot_titre(phrase,words):\n",
    "    l={}\n",
    "    mots=titles.split()\n",
    "    nb=0\n",
    "    for w in words:\n",
    "        nb=nb+mots.count(w)\n",
    "    l[phrase]=nb\n",
    "    return l\n",
    "def Pos_ph_texte():\n",
    "    l={}\n",
    "    if input_segmented.index(phrase)==0:\n",
    "        l[phrase]=1\n",
    "    else:\n",
    "        l[phrase]=0\n",
    "    return l\n",
    "\n",
    "def Nb_exp_bonus(phrase,words):\n",
    "    l ={}\n",
    "    nb=0\n",
    "    for w in words:\n",
    "        nb=nb+bonus.count(w)\n",
    "    l[phrase]=nb   \n",
    "    return l\n",
    "def Nb_exp_stigma(phrase,words):\n",
    "    l ={}\n",
    "    nb=0\n",
    "    for w in words:\n",
    "        nb=nb+sigma.count(w)\n",
    "    l[phrase]=nb   \n",
    "    return l\n",
    "\n",
    "def Idf(phrase,words):\n",
    "    l={}\n",
    "    idf=0\n",
    "    for w in words:\n",
    "        nb=0\n",
    "        for p in phrases:\n",
    "            if p.find(w):\n",
    "                nb=nb+1\n",
    "        if nb!=0:\n",
    "            idf=idf+math.log(nbr_phrase/nb)\n",
    "    l[phrase]=idf\n",
    "    return l\n",
    "def Tf(phrase,words):\n",
    "    l={}\n",
    "    nb=0\n",
    "    t=len(input_segmented)\n",
    "    for w in words:\n",
    "        nb=nb+(input_segmented.count(w)/t)\n",
    "    l[phrase]=nb\n",
    "    return l\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrases=[]\n",
    "words=[]\n",
    "labesl_phrase ={}\n",
    "position_phrase_text = {}\n",
    "number_word_title ={}\n",
    "text_position = {}\n",
    "bonus_phrase = {}\n",
    "sigma_phrase = {}\n",
    "tf = {}\n",
    "idf = {}\n",
    "\n",
    "\n",
    "phrases=input_segmented.split(\"\\n\")\n",
    "nbr_phrase=len(phrases)\n",
    "for phrase in phrases:\n",
    "    words=phrase.split(\" \")\n",
    "    labesl_phrase.update(label(phrase))\n",
    "    position_phrase_text.update(PositionPhTexte(phrase))\n",
    "    number_word_title.update(Nb_mot_titre(phrase,words))\n",
    "    text_position.update(PositionPhTexte(phrase))\n",
    "    bonus_phrase.update(Nb_exp_bonus(phrase,words))\n",
    "    sigma_phrase.update(Nb_exp_stigma(phrase,words))\n",
    "    tf.update(Tf(phrase,words))\n",
    "    idf.update(Idf(phrase,words))\n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data={\"c1\":list(critere1.values()),\"c2\":list(critere2.values()),\"c3\":list(critere3.values()),\"c4\":list(critere4.values()),\"c5\":list(critere5.values()),\"c6\":list(critere6.values()),\"c7\":list(critere9.values()),\"label\":list(critere0.values())}\n",
    "df= pd.DataFrame.from_dict(data)\n",
    "df.to_csv(r'data.csv',sep='\\t')\n",
    "X = df.drop('label', axis=1)\n",
    "y = df['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20)\n",
    "svclassifier = SVC(kernel='linear')\n",
    "svclassifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = svclassifier.predict(X_test)\n",
    "\n",
    "f=open(\"result.txt\", \"w\" , encoding=\"utf8\")\n",
    "f.write(\"%s \\n\" %confusion_matrix(y_test,y_pred))\n",
    "f.write(\" %s\" % classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
